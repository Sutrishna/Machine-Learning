{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VODKA CASE STUDY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Resp No</th>\n",
       "      <th>PANEL</th>\n",
       "      <th>CENTRE</th>\n",
       "      <th>MAIN_BRND</th>\n",
       "      <th>AGE</th>\n",
       "      <th>AGES</th>\n",
       "      <th>Plcmnt_Ordr</th>\n",
       "      <th>Prod</th>\n",
       "      <th>Q2A</th>\n",
       "      <th>Q2B</th>\n",
       "      <th>...</th>\n",
       "      <th>Q5A_att5</th>\n",
       "      <th>Q5A_att6</th>\n",
       "      <th>Q5A_att7</th>\n",
       "      <th>Q5A_att8</th>\n",
       "      <th>Q5B_att1</th>\n",
       "      <th>Q5B_att2</th>\n",
       "      <th>Q5B_att3</th>\n",
       "      <th>Q5B_att4</th>\n",
       "      <th>Q5B_att5</th>\n",
       "      <th>Q6_Int_p (Y=1,N=2)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Resp No  PANEL  CENTRE  MAIN_BRND  AGE  AGES  Plcmnt_Ordr  Prod  Q2A  Q2B  \\\n",
       "0        1      2       1          2   34     2            1     2    7    3   \n",
       "1        1      2       1          2   34     2            2     3    8    5   \n",
       "2        1      2       1          2   34     2            3     1    4    5   \n",
       "3        2      3       1          2   26     1            1     3    7    4   \n",
       "4        2      3       1          2   26     1            2     1    9    2   \n",
       "\n",
       "          ...          Q5A_att5  Q5A_att6  Q5A_att7  Q5A_att8  Q5B_att1  \\\n",
       "0         ...                 7         7         7         7         3   \n",
       "1         ...                 8         7         8         8         5   \n",
       "2         ...                 7         7         6         7         5   \n",
       "3         ...                 7         8        10         8         3   \n",
       "4         ...                 9        10        10         9         3   \n",
       "\n",
       "   Q5B_att2  Q5B_att3  Q5B_att4  Q5B_att5  Q6_Int_p (Y=1,N=2)  \n",
       "0         4         4         4         3                   2  \n",
       "1         5         5         5         3                   2  \n",
       "2         5         3         5         5                   2  \n",
       "3         3         3         3         3                   1  \n",
       "4         3         4         4         3                   1  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel(\"FINALdatablindtest.xls\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Resp No', 'PANEL', 'CENTRE', 'MAIN_BRND', 'AGE', 'AGES', 'Plcmnt_Ordr',\n",
       "       'Prod', 'Q2A', 'Q2B', 'Q3A', 'Q3B', 'Q5A_att1', 'Q5A_att2', 'Q5A_att3',\n",
       "       'Q5A_att4', 'Q5A_att5', 'Q5A_att6', 'Q5A_att7', 'Q5A_att8', 'Q5B_att1',\n",
       "       'Q5B_att2', 'Q5B_att3', 'Q5B_att4', 'Q5B_att5', 'Q6_Int_p (Y=1,N=2)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overall Likeability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5A_att1 gives the overall likability of the product hence we will verify the overall likability of the three products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Prod</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q5A_att1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22</td>\n",
       "      <td>16</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>39</td>\n",
       "      <td>43</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>74</td>\n",
       "      <td>106</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>123</td>\n",
       "      <td>152</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>217</td>\n",
       "      <td>192</td>\n",
       "      <td>218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>181</td>\n",
       "      <td>140</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>91</td>\n",
       "      <td>90</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Prod        1    2    3\n",
       "Q5A_att1               \n",
       "0           2    2    0\n",
       "1           0    1    1\n",
       "2           0    2    4\n",
       "3          11   16   14\n",
       "4          22   16   26\n",
       "5          39   43   59\n",
       "6          74  106   99\n",
       "7         123  152  118\n",
       "8         217  192  218\n",
       "9         181  140  136\n",
       "10         91   90   85"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = pd.crosstab(data['Q5A_att1'],data['Prod'])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x233845993c8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a.plot.bar(figsize=(15,5),width=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are checking the overall likeability we will be checking the scores of Q5A_att1 ratings of 9 and 10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The total % of people who have rated the products 9 and 10 are as below.\n",
    "- Prod 1 = 35.80%\n",
    "- Prod 2 = 30.02%\n",
    "- Prod 3 = 29.01%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have got the Percentage likability of the products we will perform a Z - Test to verify whether there is significant difference between the two products.\n",
    "\n",
    "For the Z - Test we will be considering the below values, this will be a two tailed test because we need to check for significant difference which can be greater or less.\n",
    "    - PROD1:\n",
    "        - n = 760\n",
    "        - CI = 95%\n",
    "        - sample proportion - 0.358\n",
    "\n",
    "\n",
    "From the z statistic the p-critical values, 0.324 < p < 0.392"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    - PROD2:\n",
    "        - n = 760\n",
    "        - CI = 95%\n",
    "        - sample proportion - 0.302\n",
    "\n",
    "\n",
    "From the z statistic the p-critical values, 0.27 < p < 0.334"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there is an overlap between the two ranges we can conclude that there is no significant difference between the Two products."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drivers of Overall Likeability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Overall Likeability of the product is linked with 7 more attributes.\n",
    "\n",
    "- 5A_Attr2 â€“ Likeability of Aroma\n",
    "- 5A_Attr3 â€“ Likeability of Taste\n",
    "- 5A_Attr4 â€“ Likeability of Smoothness\n",
    "- 5A_Attr5 â€“ Likeability of Flavour\n",
    "- 5A_Attr6 â€“ Likeability of Throat-feel when the vodka goes down\n",
    "- 5A_Attr7 â€“ Likeability of After-taste\n",
    "- 5A_Attr8 â€“ Likeability of Mouth-feel when the vodka is sipped\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to verify what all attributes drive the overall likeability of the product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do this we can do a Simple Linear Regression keeping the overall likeability column as the Target and the Rest of the attributes as Predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q5A_att1</th>\n",
       "      <th>Q5A_att2</th>\n",
       "      <th>Q5A_att3</th>\n",
       "      <th>Q5A_att4</th>\n",
       "      <th>Q5A_att5</th>\n",
       "      <th>Q5A_att6</th>\n",
       "      <th>Q5A_att7</th>\n",
       "      <th>Q5A_att8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Q5A_att1  Q5A_att2  Q5A_att3  Q5A_att4  Q5A_att5  Q5A_att6  Q5A_att7  \\\n",
       "0         7         6         7         7         7         7         7   \n",
       "1         8         8         8         8         8         7         8   \n",
       "2         7         6         7         8         7         7         6   \n",
       "3        10         8         8         8         7         8        10   \n",
       "4         9         9         9         9         9        10        10   \n",
       "\n",
       "   Q5A_att8  \n",
       "0         7  \n",
       "1         8  \n",
       "2         7  \n",
       "3         8  \n",
       "4         9  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "likeability = data[['Q5A_att1', 'Q5A_att2', 'Q5A_att3','Q5A_att4', 'Q5A_att5', 'Q5A_att6', 'Q5A_att7', 'Q5A_att8']]\n",
    "likeability.to_csv('likeability.csv',index=False)\n",
    "likeability.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will Build a simple linear regression model considering only one attribute i.e. Q5A_att2(Aroma)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:               Q5A_att1   R-squared:                       0.523\n",
      "Model:                            OLS   Adj. R-squared:                  0.523\n",
      "Method:                 Least Squares   F-statistic:                     2496.\n",
      "Date:                Wed, 13 Jun 2018   Prob (F-statistic):               0.00\n",
      "Time:                        21:48:41   Log-Likelihood:                -3593.1\n",
      "No. Observations:                2280   AIC:                             7190.\n",
      "Df Residuals:                    2278   BIC:                             7202.\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      2.6425      0.102     25.888      0.000       2.442       2.843\n",
      "Q5A_att2       0.6655      0.013     49.960      0.000       0.639       0.692\n",
      "==============================================================================\n",
      "Omnibus:                      322.314   Durbin-Watson:                   1.774\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1964.772\n",
      "Skew:                          -0.508   Prob(JB):                         0.00\n",
      "Kurtosis:                       7.433   Cond. No.                         32.4\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.formula.api as sm\n",
    "m = sm.ols(formula=\"Q5A_att1~Q5A_att2\",data=likeability).fit()\n",
    "print(m.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above summary we can observe that the explained variance by the model using only one predictor is just 52.3%.\n",
    "\n",
    "- The F-Statistic(F = (SSR/(n-1))/SSE/(n-p-1)) is high and the p-value of the F-Statistic is also significant.\n",
    "- The r2 and adj r2 values are 0.523 which means that this model with one attribute is able to explain only 52.3% of the variance\n",
    "- The t statistic for the predictor is significantly high and its p-value is near to zero which means that this variable is significantly contributing in the explanation of variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will do the same linear regression with all the predictor variables identified.\n",
    "- 5A_Attr2 â€“ Likeability of Aroma\n",
    "- 5A_Attr3 â€“ Likeability of Taste\n",
    "- 5A_Attr4 â€“ Likeability of Smoothness\n",
    "- 5A_Attr5 â€“ Likeability of Flavour\n",
    "- 5A_Attr6 â€“ Likeability of Throat-feel when the vodka goes down\n",
    "- 5A_Attr7 â€“ Likeability of After-taste\n",
    "- 5A_Attr8 â€“ Likeability of Mouth-feel when the vodka is sipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:               Q5A_att1   R-squared:                       0.775\n",
      "Model:                            OLS   Adj. R-squared:                  0.774\n",
      "Method:                 Least Squares   F-statistic:                     1117.\n",
      "Date:                Wed, 13 Jun 2018   Prob (F-statistic):               0.00\n",
      "Time:                        21:48:42   Log-Likelihood:                -2736.5\n",
      "No. Observations:                2280   AIC:                             5489.\n",
      "Df Residuals:                    2272   BIC:                             5535.\n",
      "Df Model:                           7                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      0.5755      0.082      7.042      0.000       0.415       0.736\n",
      "Q5A_att2       0.1593      0.014     11.493      0.000       0.132       0.186\n",
      "Q5A_att3       0.2821      0.019     14.529      0.000       0.244       0.320\n",
      "Q5A_att4       0.1072      0.017      6.181      0.000       0.073       0.141\n",
      "Q5A_att5       0.0783      0.018      4.454      0.000       0.044       0.113\n",
      "Q5A_att6       0.0871      0.018      4.721      0.000       0.051       0.123\n",
      "Q5A_att7       0.0347      0.020      1.730      0.084      -0.005       0.074\n",
      "Q5A_att8       0.1890      0.021      9.070      0.000       0.148       0.230\n",
      "==============================================================================\n",
      "Omnibus:                      144.565   Durbin-Watson:                   1.753\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              500.205\n",
      "Skew:                          -0.238   Prob(JB):                    2.41e-109\n",
      "Kurtosis:                       5.245   Cond. No.                         98.2\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.formula.api as sm\n",
    "m = sm.ols(formula=\"Q5A_att1~Q5A_att2+Q5A_att3+Q5A_att4+Q5A_att5+Q5A_att6+Q5A_att7+Q5A_att8\",data=likeability)\n",
    "AR = m.fit()\n",
    "print(AR.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of Squared Residuals =  1472.1557173483202\n"
     ]
    }
   ],
   "source": [
    "print(\"Sum of Squared Residuals = \",AR.ssr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that in our model r2 value has significantly increased and all the coefficients for all the attributes are significant.\n",
    "\n",
    "- The F-Statistic(F = (SSR/(n-1))/SSE/(n-p-1)) is high and the p-value of the F-Statistic is also significant.\n",
    "- The r2 and adj r2 values are 0.775 which means that this model with all the attributes is able to explain only 77.5% of the variance\n",
    "- The t static for all the predictors is significantly high and their p-value is near to zero which means that the variables together significantly contribute in the explaination of variance.\n",
    "- The p-value of Q5A_att7(After-taste) is > 0.05 so we can repeat the regression removing the variable and check our results.\n",
    "- Sum of Squared Residuals =  513.20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:               Q5A_att1   R-squared:                       0.775\n",
      "Model:                            OLS   Adj. R-squared:                  0.774\n",
      "Method:                 Least Squares   F-statistic:                     1302.\n",
      "Date:                Wed, 13 Jun 2018   Prob (F-statistic):               0.00\n",
      "Time:                        21:48:42   Log-Likelihood:                -2738.0\n",
      "No. Observations:                2280   AIC:                             5490.\n",
      "Df Residuals:                    2273   BIC:                             5530.\n",
      "Df Model:                           6                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      0.5892      0.081      7.241      0.000       0.430       0.749\n",
      "Q5A_att2       0.1604      0.014     11.583      0.000       0.133       0.188\n",
      "Q5A_att3       0.2880      0.019     15.049      0.000       0.250       0.325\n",
      "Q5A_att4       0.1102      0.017      6.383      0.000       0.076       0.144\n",
      "Q5A_att5       0.0835      0.017      4.814      0.000       0.049       0.117\n",
      "Q5A_att6       0.0937      0.018      5.183      0.000       0.058       0.129\n",
      "Q5A_att8       0.2005      0.020     10.146      0.000       0.162       0.239\n",
      "==============================================================================\n",
      "Omnibus:                      143.007   Durbin-Watson:                   1.755\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              488.447\n",
      "Skew:                          -0.238   Prob(JB):                    8.61e-107\n",
      "Kurtosis:                       5.217   Cond. No.                         90.5\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.formula.api as sm\n",
    "m = sm.ols(formula=\"Q5A_att1~Q5A_att2+Q5A_att3+Q5A_att4+Q5A_att5+Q5A_att6+Q5A_att8\",data=likeability)\n",
    "AR = m.fit()\n",
    "print(AR.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of Squared Residuals =  1474.0939302686584\n"
     ]
    }
   ],
   "source": [
    "print(\"Sum of Squared Residuals = \",AR.ssr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe the following differences in the output after removing Q5A_att7(After-Taste):\n",
    "\n",
    "- The F Statistic value has increased from 1117 to 1302.\n",
    "- There is no change in the R2 value.\n",
    "- The sum of squared residuals has increased from 1472.155 to 1474.09 which is not a significant increase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### From the Above observations we can say that After-taste doesn't significantly contribute towards the overall Likeability of the product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Collinearity among variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q5A_att1</th>\n",
       "      <th>Q5A_att2</th>\n",
       "      <th>Q5A_att3</th>\n",
       "      <th>Q5A_att4</th>\n",
       "      <th>Q5A_att5</th>\n",
       "      <th>Q5A_att6</th>\n",
       "      <th>Q5A_att7</th>\n",
       "      <th>Q5A_att8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Q5A_att1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.723069</td>\n",
       "      <td>0.823922</td>\n",
       "      <td>0.766472</td>\n",
       "      <td>0.765972</td>\n",
       "      <td>0.765213</td>\n",
       "      <td>0.770606</td>\n",
       "      <td>0.799983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q5A_att2</th>\n",
       "      <td>0.723069</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.699165</td>\n",
       "      <td>0.650235</td>\n",
       "      <td>0.699211</td>\n",
       "      <td>0.644325</td>\n",
       "      <td>0.658032</td>\n",
       "      <td>0.652336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q5A_att3</th>\n",
       "      <td>0.823922</td>\n",
       "      <td>0.699165</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.777731</td>\n",
       "      <td>0.783251</td>\n",
       "      <td>0.749416</td>\n",
       "      <td>0.790696</td>\n",
       "      <td>0.796745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q5A_att4</th>\n",
       "      <td>0.766472</td>\n",
       "      <td>0.650235</td>\n",
       "      <td>0.777731</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.730227</td>\n",
       "      <td>0.783715</td>\n",
       "      <td>0.758622</td>\n",
       "      <td>0.761744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q5A_att5</th>\n",
       "      <td>0.765972</td>\n",
       "      <td>0.699211</td>\n",
       "      <td>0.783251</td>\n",
       "      <td>0.730227</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.742777</td>\n",
       "      <td>0.772320</td>\n",
       "      <td>0.768208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q5A_att6</th>\n",
       "      <td>0.765213</td>\n",
       "      <td>0.644325</td>\n",
       "      <td>0.749416</td>\n",
       "      <td>0.783715</td>\n",
       "      <td>0.742777</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.795996</td>\n",
       "      <td>0.814465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q5A_att7</th>\n",
       "      <td>0.770606</td>\n",
       "      <td>0.658032</td>\n",
       "      <td>0.790696</td>\n",
       "      <td>0.758622</td>\n",
       "      <td>0.772320</td>\n",
       "      <td>0.795996</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.830628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q5A_att8</th>\n",
       "      <td>0.799983</td>\n",
       "      <td>0.652336</td>\n",
       "      <td>0.796745</td>\n",
       "      <td>0.761744</td>\n",
       "      <td>0.768208</td>\n",
       "      <td>0.814465</td>\n",
       "      <td>0.830628</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Q5A_att1  Q5A_att2  Q5A_att3  Q5A_att4  Q5A_att5  Q5A_att6  \\\n",
       "Q5A_att1  1.000000  0.723069  0.823922  0.766472  0.765972  0.765213   \n",
       "Q5A_att2  0.723069  1.000000  0.699165  0.650235  0.699211  0.644325   \n",
       "Q5A_att3  0.823922  0.699165  1.000000  0.777731  0.783251  0.749416   \n",
       "Q5A_att4  0.766472  0.650235  0.777731  1.000000  0.730227  0.783715   \n",
       "Q5A_att5  0.765972  0.699211  0.783251  0.730227  1.000000  0.742777   \n",
       "Q5A_att6  0.765213  0.644325  0.749416  0.783715  0.742777  1.000000   \n",
       "Q5A_att7  0.770606  0.658032  0.790696  0.758622  0.772320  0.795996   \n",
       "Q5A_att8  0.799983  0.652336  0.796745  0.761744  0.768208  0.814465   \n",
       "\n",
       "          Q5A_att7  Q5A_att8  \n",
       "Q5A_att1  0.770606  0.799983  \n",
       "Q5A_att2  0.658032  0.652336  \n",
       "Q5A_att3  0.790696  0.796745  \n",
       "Q5A_att4  0.758622  0.761744  \n",
       "Q5A_att5  0.772320  0.768208  \n",
       "Q5A_att6  0.795996  0.814465  \n",
       "Q5A_att7  1.000000  0.830628  \n",
       "Q5A_att8  0.830628  1.000000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "likeability.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2338743a630>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEgCAYAAACuDOSlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3X+0nXV95v33JYQQDBAmOnRKIAkYRHGUNJGKDD8a/AHOaoTCcghWmjJ9UoaxzODIIqKL+sjwyIAuq42zXLFVh4rwWAKBjggyKBTFVEhDIsGHhgSUiK02gIQShORczx/3fWC72eec+yRn7/0951wv172y71/7e+0E92d/v/cv2SYiIqLdq/odICIiypQCERERHaVARERERykQERHRUQpERER0lAIREREdpUBERERHKRAREdFRCkRERHS0d78D9NqL/7yl75eOn7Pgon5HAOAjA/1OAN961f79jhBtpvT9/yFw5Au7+h0BgN/9x+u0p+8xmu+cKa85fI/bG0uTrkBERPTUQBnFbnekQEREdJML6KrvphSIiIhuGkiBiIiIDpweREREdJQeREREdJQeREREdLTrxX4n2G0pEBER3ZQhpoiI6CQHqSMiorNx3INodC8mSbMk3Sxpk6QtklZImippjqQdkh6opy+07TdfkiW9e3cDSrq05fUMSRe0rb9N0tOS/vfuthER0TUeaD4VZsQCIUnAjcBq2/OAecA04Kp6k822j6mn89t2XwJ8t/5zd13a8noGcEHb+quBD+zB+0dEdM+uF5tPhWkyxLQIeN72lwFs75J0EfBj4ItD7VQXlrOAdwL3SNrX9vPDbL8aOBTYF/is7ZWSrgSmSXoA2AjsBRxRz99h+2Lbd0o6ucmHjYjouQk+xHQ0sLZ1ge1ngMeoCsxcSesk3S3phJbNjgcetb0ZuAt4zwjtnGd7AbAQuFDSTNvLgR117+T9wHJe7rFc3CA7AJKWSbpf0v1/cc11TXeLiNhz43iIqUkPQkCn29UKmAocZnubpAXAaklH1wVkCXB9ve31VMNANw7TzoWSzqhfH0o1lLWtQb4R2V4JrIQybvcdEZPIOO5BNCkQG4EzWxdIOgA4GNhgeweA7bWSNgNHSlpX77NY0kepislMSfvb3t7eQD1E9A7gONvPSbqLaqgpImJcs8fv7b6bDDHdCewn6VwASXsBnwZWANPreSQdTvWrfwvVl/1624fanmN7NrAKOH2INg4EnqqLw1HA21rWvShpSv16O5AnzETE+DGOh5hGLBC2DZwBnCVpE9Wwz4DtK4ATgQ2S1gM3AOfbfpJqeOmmtrdaBZwzRDO3AXtL2gBcDqxpWbeybuNa29uA70l6UNLVAJLuAf4aOEXS1j05pTYiYszt2tl8KkyjC+VsPw4sBpD0duA6SQtsr6L64m/ffmmHZbcAtwzx/r8CThti3SXAJS3z57StP+EVO0VElGIyPVHO9r3A7C5kiYiYeAocOmqq0ZXUY0XSzJarrlunmb3MERHRMwMDzacGJJ0q6WFJj0ha3mH9bEl3Stog6S5Js1rWHSbpW5J+JOkhSXOGa6un92KqjyEc08s2IyL6agx7EPVJQZ+nugB5K3CfpFtsP9Sy2aeAa2z/L0mLgE/y8t0mrgGusH2HpOnAsOF62oOIiJh0xrYHcSzwiO0ttl+gusbsvW3bvJHq7FOA7wyul/RGYG/bdwDYftb2c8M1lgIREdFF3vVi46mBQ4DHW+a31starefla9fOAPavh/GPBJ6WdGN994urBy9TGEoKREREN42iB9F6W6B6Wtb2burQQvvdIT4MnFRfsHwS8FNgJ9UhhRPq9W8FDgeWDhc9z4OIiOimURyDaL0t0BC2Ut2KaNAs4Im293gC+D2A+jjDmbZ/KWkrsM72lnrdaqqLkv9yqMYmXYE4Z8FF/Y7A19Z+pt8RADj5LX/U7wis/cW6fkcAYMHM1/U7An/3i4f7HQGAV+/T/7vcvFDIRWM7xuJNxvZeTPcB8yTNpeoZnE3bBciSXgM86epRdh8BvtSy70GSXmv7F1R36r5/uMYyxBQR0U1jeKsN2zuBDwK3Az8Cvm57o6RPSFpcb3Yy8LCkf6C6Z94V9b67qIaX7pT0Q6rhqiEf2QCTsAcREdFTY9wbsn0rcGvbsstaXt9AdeujTvveAby5aVspEBER3TTBb/cdERG7KwUiIiI6Gsf3YkqBiIjopvQgIiKio/QgIiKio0Ku6dgdKRAREd2UIaaIiOhoHBeIRldSS5ol6WZJmyRtkbRC0lRJcyTtaHnwzxfa9psvyXvynGhJl7a8niHpgpb5YyR9X9LG+uEY/2F324mI6Aq7+VSYEQuEJAE3AqttzwPmAdOAq+pNNts+pp7Ob9t9CfDd+s/ddWnL6xnABS3zzwHn2j4aOBX4M0kz9qCtiIixNcZPlOulJkNMi4DnbX8Zqvt5SLoI+DHD3MejLixnUT356B5J+9p+fpjtV1PdpXBf4LO2V0q6Epgm6QFgI7AXcEQ9f4ftiwf3t/2EpJ8DrwWebvC5IiK6r8Av/qaaFIijgbWtC2w/I+mxev+59X3HnwE+ZvueerPjgUdtb5Z0F/Aeqp7IUM6z/aSkaVSP0Vtle7mkD9o+BqB+fuqbBudbSToW2AfY3GHdMmAZwG/9qzdz+PQ5DT52RMQYGMdnMTU5BiFe+UCKweVTgcNszwc+BHxN0gH1+iVUj8Oj/nOkYaYLJa0H1lD1JOY1yFYFkf4N8FfAH9a3uP01tlfaXmh7YYpDRPTUOD4G0aQHsZGXH18HQF0EDgY22N4BYHutpM3AkXWP4kxgsaSPUhWTmZL2t729vQFJJwPvAI6z/Vzd42h0U/o6yzeoei9rmuwTEdEz43iIqUkP4k5gP0nnAtTPMP00sAKYPvhMU0mHU/3q30L1Zb/e9qG259ieDawCTh+ijQOBp+ricBTVU44GvShpSv16O7D/4ApJ+wA3AdfY/utGnzgiopfG8UHqEQuEbVM9+PosSZuAbcCA7SuAE4EN9dDQDcD5tp+kGk66qe2tVtH25KMWtwF7S9oAXE41zDRoZd3Gtba3Ad+T9KCkq4H31RmWtpxq+4rjExERfTOGDwzqtUYXytl+HFgMIOntwHWSFtheRfXF37790g7LbgFuGeL9fwWcNsS6S4BLWubbi8xXm3yGiIh+8M5d/Y6w20Z9JbXte4HZXcgSETHxFNgzaKqnt9qQNJPqmEa7U+rho4iIiWWgvLOTmuppgaiLQI4RRMTkUeDB56Zys76IiG5KgYiIiI4KvACuqRSIiIhumkxnMUVExCjkLKbx4yMF/Fud/JY/6ncEAO5a/xf9jsBfzr+s3xEAmFLAKMBxv3lwvyMAsOCFRo+J6aqp4/jMn1cYx59l0hWIiIhecg5SR0RER+lBRERER+P4GET/BxsjIiaynbuaTw1IOlXSw5IekbS8w/rZku6UtEHSXZJmtaz7A0mb6ukPRmorBSIiopsG3HwaQf14hc9T3dz0jcASSW9s2+xTVI9AeDPwCeCT9b7/CvhT4LeBY4E/lXTQcO2lQEREdNPY3u77WOAR21tsv0D1tM73tm3zRl6+5913Wta/G7jD9pO2nwLuAE4drrEUiIiIbhpFD0LSMkn3t0zL2t7tEODxlvmt9bJW63n5KaBnAPvXN0ptsu+vyUHqiIguGs1prrZXUj0kbSjqtFvb/IeBFZKWAn8L/BTY2XDfX5MCERHRTTvH9CymrcChLfOzgCdaN7D9BPB7AJKmA2fa/qWkrcDJbfveNVxjGWKKiOimsT0GcR8wT9JcSfsAZ9P2pE5Jr5E0+N3+EeBL9evbgXdJOqg+OP2uetmQUiAiIrppDM9isr0T+CDVF/uPgK/b3ijpE5IW15udDDws6R+Ag4Er6n2fBC6nKjL3AZ+olw2pUYGQNEvSzfW5s1skrZA0VdIcSTskPVBPX2jbb74kS3p3k3aGaPvSltczJF3QMj9b0tq67Y2Szt/ddiIiusEDbjw1ej/7VttH2j7C9uCX/2W2b6lf32B7Xr3NH9n+Vcu+X7L9unr68khtjVggJAm4EVhtex4wD5gGXFVvstn2MfXU/gW9BPhu/efuurTl9Qzggpb5nwFvt30M1bm9yyX95h60FRExtsawB9FrTXoQi4DnB6uN7V3ARcC5wPShdqoLy1nAUqpxr32Ha0TS6ro3sHHw1C5JVwLT6h7CtcCVwBH1/NW2X2ipjlOH+jytp47d+OxjDT5yRMQYGRhoPhWmyVlMRwNrWxfYfkbSY/X+cyWtA54BPmb7nnqz44FHbW+WdBfwHqqeyFDOs/2kpGnAfZJW2V4u6YN1DwFJc4A3Dc7Xyw4FvgG8Dri4PoL/a1pPHfv7Q99bXpmOiIlrbM9i6qkmPQjR+VxZUf1qP8z2fOBDwNckHVCvX0J1lR/1nyMNM10oaT2whuo0rnkNsmH78fqS8tcBfyCpjJvqR0QAthtPpWlSIDYCC1sX1EXgYGCD7W0AttcCm4Ej6/uFnAlcVvc0/hw4TdL+nRqQdDLwDuA4228B1gHDDkm1q3sOG4ETRrNfRERXTfBjEHcC+0k6F166WdSngRXA9HoeSYdT/erfQvVlv972obbn2J4NrAJOH6KNA4GnbD8n6SjgbS3rXpQ0pX69HXipyNRnV02rXx9ENaz1cIPPFBHRGxO5QLjq95wBnCVpE7ANGKhPrzoR2FAPDd0AnF+fV7sEuKntrVYB5wzRzG3A3pI2UJ2nu6Zl3cq6jWvr3sr3JD0o6WrgDcDf1e3fDXzK9g8bffKIiB4Y69Nce6nRrTZsPw4sBpD0duA6SQtsr6L64m/ffmmHZbfQdsVfy7pfUd2+ttO6S4BLWubbi8ybm3yGiIi+KPCLv6lR34vJ9r3A7C5kiYiYcLxzEhWIPVHfcvbODqtOGTzYHRExoUymHsSeqIvAMSNuGBExUYzfyyByu++IiG4q8eBzUykQERHdlB5ERER0koPU48i3XtXxYu6eWvuLdf2OAMBfzr+s3xH4j+s+0e8IAJy34MP9jsCiF/frdwQAHp7S/y+0vTo+HbP3fm8M3qPZc4DKNOkKRERET6VAREREJ+lBREREZykQERHRSXoQERHR0cDOfifYfSkQERHd5DLOyNodKRAREV2UIaaIiOjIA+lBREREB+lBRERERwO70oOIiIgOxvMQ04jPpAaQNEvSzZI2SdoiaYWkqZLmSNoh6YF6+kLbfvMlWdK7dzegpEtbXs+QdEGHbQ6Q9FNJK3a3nYiIbrCbT6UZsUBIEnAjsNr2PGAeMA24qt5ks+1j6un8tt2XAN+t/9xdl7a8ngG8okAAlwN370EbERFd4QE1nkrTpAexCHje9pcBbO8CLgLOBaYPtVNdWM4ClgLvkrTvcI1IWi1praSNkpbVy64EptW9k2uBK4Ej6vmr620WAAcD3xrmvZdJul/S/T94dlODjxwRMTbGukBIOlXSw5IekbS8w/rDJH1H0jpJGyS9p8P6ZyWNeAvjJgXiaGBt6wLbzwCPUR3DmFsHuVvSCS2bHQ88anszcBfwayE7OM/2AmAhcKGkmbaXAzvq3sn7geW83GO5WNKrgE8DFw/3xrZX2l5oe+Gx0+c1+MgREWNjLIeYJO0FfB44DXgjsETSG9s2+xjwddvzgbOB/9m2/jPAN5tkb3KQWkCn6AKmAofZ3lb/kl8t6ei6gCwBrq+3vR74ANVQ1VAulHRG/fpQqqGsbSNkuwC41fbjVYclIqIsA7saHept6ljgEdtbACRdD7wXeKhlGwMH1K8PBJ4YXCHpdGAL8C9NGmtSIDYCZ7YukHQA1bDOBts7AGyvlbQZOFLSunqfxZI+SlVMZkra3/b29gYknQy8AzjO9nOS7gKGHZKqHQecUB+4ng7sI+nZuucREdF3o7kOoh5eX9ayaKXtlS3zhwCPt8xvBX677W0+DnxL0p8Ar6b6bkXSq4FLgHcCjZ6Q1aS03QnsJ+ncupG9qIZ1VgDT63kkHU71q39LHWi97UNtz7E9G1gFnD5EGwcCT9XF4SjgbS3rXpQ0pX69HXjpkXC232/7MNtz6g98TYpDRJRkwGo8tQ6H19PKtrfrNFTSPsKzBPiK7VlUQ/t/VQ/H/9/AZ2w/2zT7iAXCtoEzgLMkbaIa9hmwfQVwIrBB0nrgBuB820/WAW9qe6tVwDlDNHMbsLekDVRnJK1pWbeybuNa29uA70l6cPAgdUREyWw1nhrYSjUEP2gWLUNItf8IfL1q29+nGo15DVVP4ypJjwH/FbhU0geHa6zRhXK2HwcWA0h6O3CdpAW2V1F98bdvv7TDsluAW4Z4/19RHXTptO4Sqm7R4HzHImP7K8BXhv8kERG9Ncanr94HzJM0F/gp1UHo9u/EnwCnAF+R9AaqAvEL2y+dRCTp48Cztoe9dmzUV1LbvheYPdr9IiImo7G8AM72zvpX/+3AXsCXbG+U9Ang/vqH+H8DvijpIqrhp6X1SNCo9fRWG5JmUh3TaHdKPXwUETGh7Brbs5iwfStwa9uyy1peP0R1mcFw7/HxJm31tEDUReCYXrYZEdFPDY8tFCk364uI6KIS77HUVApEREQXDaQHERERnWSIKUZlwczX9TsCAFMK6Pqet6DRBZ1d96W1n+p3BC5a+JF+RwBg3sCUkTfqshf7HWAM7SrwLq1NpUBERHRRehAREdFRjkFERERHBYzk7rYUiIiILkoPIiIiOsoxiIiI6GhXxzt0jw8pEBERXTQwjg9CpEBERHTRQHoQERHRiVMgIiKik1E8kro4KRAREV00nnsQjZ5kIWmWpJslbZK0RdIKSVMlzZG0Q9ID9fSFtv3mS7Kkd+9uQEmXtryeIemCtvW7Wtrv+EjTiIh+2TmKqTQjFghJAm4EVtueB8wDpgFX1Ztstn1MPZ3ftvsS4Lv1n7vr0pbXM4AL2tbvaGl/8R60ExEx5owaT6Vp0oNYBDxv+8sAtncBFwHnAtOH2qkuLGcBS4F3Sdp3uEYkrZa0VtJGScvqZVcC0+rewbXAlcAR9fzVDbIPvvcySfdLuv8Hz25qultExB4bUPOpNE0KxNHA2tYFtp8BHqM6hjFX0jpJd0s6oWWz44FHbW8G7gLeM0I759leACwELpQ00/ZyXu4hvB9Yzss9lovr/fatv/zXSDq90xvbXml7oe2Fx06f1+AjR0SMjQHUeCpNk4PUovP9pgRMBQ6zvU3SAmC1pKPrArIEuL7e9nrgA1RDVUO5UNIZ9etDqYaytjXId5jtJyQdDnxb0g/rohQR0Xfj+Dq5RgViI3Bm6wJJBwAHAxts7wCwvVbSZuBISevqfRZL+ihVMZkpaX/b29sbkHQy8A7gONvPSboLGHZIapDtJ+o/t9T7zQdSICKiCDtVXs+gqSZDTHcC+0k6F0DSXsCngRXA9Hqe+hf8PGAL1Zf9etuH2p5jezawCug4BAQcCDxVF4ejgLe1rHtR0uAjrrYD+w+ukHSQpKn169dQDWs91OAzRUT0hEcxlWbEAmHbwBnAWZI2UQ37DNi+AjgR2CBpPXADcL7tJ6mGl25qe6tVwDlDNHMbsLekDcDlwJqWdSvrNq61vQ34nqQH64PUbwDur9v/DnCl7RSIiCjGwCim0jS6UM7248BiAElvB66TtMD2Kqov/vbtl3ZYdgvQ8ToF278CThti3SXAJS3z7UXm3zb5DBER/VDi2UlNjfpKatv3ArO7kCUiYsIp8eykpnp6qw1JM6mOabQ7pR4+ioiYUEo8ttBUTwtEXQSO6WWbERH9tHOMOxCSTgU+C+wF/IXtK9vWfwb4nXp2P+Bf255Rr7sK+PdUx5/vAP5LfZy5o9ysLyKii8ayB1GfNfp54J3AVuA+Sbe0npxj+6KW7f+E6tT/wePHxwNvrld/FziJ6kLmjhrdrC8iInbPGN9q41jgEdtbbL9AdRHye4fZfglwXf3aVNeX7UN1kfMU4J+GaywFIiKii8b4NNdDgMdb5rfWy15B0mxgLvBtANvfp7oc4Gf1dLvtHw3XWApEREQXjaZAtN5YtJ6Wtb1dp37GUKNYZwM31DdYRdLrqK4dm0VVVBZJOnG47DkG0Qd/94uH+x0BgON+8+B+R2DRi/v1OwIAFy38SL8j8Jn7P9nvCAD8zZs+1u8IvJYX+h1hzHgUB6ltr6S6OHgoW6nuVTdoFvDEENueDfznlvkzgDW2nwWQ9E2qu1b87VCNpQcREdFFY/zAoPuAeZLmStqHqgi84gJkSa8HDgK+37L4J8BJkvaub190EpAhpoiIfhnLezHZ3gl8ELid6sv967Y3SvqEpNYHpi0Brm87hfUGqhuZ/hBYT3W/vL8Zrr0MMUVEdNFY32rD9q3ArW3LLmub/3iH/XYBfzyatlIgIiK6qMSb8DWVAhER0UUpEBER0dGu8XuvvhSIiIhuSg8iIiI6yt1cIyKio4FxXCJSICIiumg8DzE1ulBO0ixJN0vaJGmLpBWSpkqaI2mHpAfq6Qtt+82XZEnv3t2Aki5teT1D0gVt6w+T9C1JP5L0kKQ5u9tWRMRYG8sL5XptxAIhScCNwGrb84B5wDTgqnqTzbaPqafz23ZfQnXP8SV7kPHSltczgAva1l8DXG37DVS3wv35HrQVETGmdqr5VJomQ0yLgOdtfxmqq/EkXQT8GPjiUDvVheUsqgdb3CNpX9vPD7P9aqqbUO0LfNb2SklXAtMkPQBspHqC0hH1/B3Al4G9bd9RZ3u2weeJiOiZ8XwMoskQ09HA2tYFtp8BHqMqMHMlrZN0t6QTWjY7HnjU9maqJxa9Z4R2zrO9AFgIXChppu3lwI66d/J+YDkv91guBo4EnpZ0Y53h6vqJS7+m9Ra6P3h2U4OPHBExNib0EBPV/cc7ZRfVU4kOsz0f+BDwNUkH1OuXUD3tiPrPkYaZLpS0HlhD1ZOY1yDb3sAJwIeBtwKHA0vbN7K90vZC2wuPnd7kbSMixsYYPzCop5oUiI1Uv+pfUheBg4ENtrcB2F5LdafAI+tf8WcCl0l6DPhz4DRJ+3dqQNLJwDuA42y/BVhHNdQ0kq3AuvrxezuB1cBvNdgvIqInBnDjqTRNCsSdwH6SzoWXHpr9aWAFMH1wSEfS4VS/+rdQfdmvt32o7Tm2ZwOrgNOHaONA4Cnbz0k6iuohFoNerO9dDrAdaC0y9wEHSXptPb8IeIiIiELsGsVUmhELRH0/8TOAsyRtArYBA7avAE4ENtRDQzcA59t+kmo46aa2t1oFnDNEM7cBe0vaAFxONcw0aGXdxrV1b+V7kh6UdHV9+9oPA3dK+iHVsNeQB84jInptPPcgGl0oZ/txYDGApLcD10laYHsV1Rd/+/ZLOyy7hQ5PPqrX/Qo4bYh1lwCXtMyf07b+DuDNTT5HRESvlfe139yor6S2fS8wuwtZIiImnBIPPjfV01ttSJpJdUyj3SmDB7sjIiYSj+M+RE8LRF0EjullmxER/ZQeREREdLQrPYiIiOikxLOTmkqBiIjoogwxRURERzlIPY5MKeDf6tX7NLmLSPcteKHR40C66uES/kGAeQNTRt6oy/7mTR/rdwQAfvfB/97vCDx87IX9jjBm0oOIiIiO0oOIiIiOdjoFIiIiOhi/5SEFIiKiq8bzaa79P0oZETGBeRT/a0LSqZIelvSIpOUd1n9G0gP19A+Snq6XHyPp+5I2Stog6T+M1FZ6EBERXTSWZzHVz9/5PPBOqgem3SfpFtsvPQfH9kUt2/8JML+efQ441/YmSb8JrJV0u+2nh2ovPYiIiC7axUDjqYFjgUfqp2i+QPU45/cOs/0S4DoA2/9ge1P9+gng58Brh9k3BSIioptG80xqScsk3d8yLWt7u0OAx1vmt9bLXkHSbGAu8O0O644F9qF6TPSQMsQUEdFFHsVprrZXUj1FcyjqtNsQ254N3FA/efPlN5D+DfBXwB/YHrbbkgIREdFFY3wW01bg0Jb5WcATQ2x7NvCfWxdIOgD4BvAx22s67tWi0RCTpFmSbpa0SdIWSSskTZU0R9KOliPmX2jbb74kS3p3k3aGaPvSltczJF3QMv87LW0/IOl5SafvblsREWNtNENMDdwHzJM0V9I+VEXgFY9ylvR64CDg+y3L9gFuAq6x/ddNGhuxQEgScCOw2vY8YB4wDbiq3mSz7WPq6fy23ZcA363/3F2XtryeAbxUIGx/Z7BtYBHVUfpv7UFbERFjaixPc7W9E/ggcDvwI+DrtjdK+oSkxS2bLgGu96+Pb70POBFY2vKjetgHuDUZYloEPG/7y3XAXZIuAn4MfHGonerCchbV6Vj3SNrX9vPDbL+aquu0L/BZ2yslXQlMk/QAsBHYCziinr/D9sUtb3EW8E3bzzX4TBERPbFr+GH+UbN9K3Br27LL2uY/3mG/rwJfHU1bTYaYjgbWtjX0DPAYVYGZK2mdpLslndCy2fHAo7Y3A3cB7xmhnfNsLwAWAhdKmml7ObCj7iW8H1jOyz2Wi9v2P5v6dK52rWcGrHl2U4OPHBExNsZ4iKmnmhQI0fkouYCpwGG25wMfAr5WHwSBuotTv76ekYeZLpS0HlhD1ZOY1yBbFaQ6Kv9vqbpdr2B7pe2Fthe+bXrjt42I2GNjfSV1LzUZYtoInNm6oC4CBwMbbO8AsL1W0mbgSEnr6n0WS/ooVTGZKWl/29vbG5B0MvAO4Djbz0m6i2qoqan3ATfZfnEU+0REdN1EvxfTncB+ks6Fly71/jSwAphezyPpcKpf/VuovuzX2z7U9hzbs4FVwFBnGB0IPFUXh6OAt7Wse1HS4NNctgP7d9j/pasFIyJKYrvxVJoRC0R9FPwM4CxJm4BtwIDtK6iOiG+oh4ZuAM63/STVF/ZNbW+1CjhniGZuA/aWtAG4nGqYadDKuo1rbW8DvifpQUlXA0iaQzUkdXeDzxsR0VMDuPFUmkYXytl+HFgMIOntwHWSFtheRfXF37790g7LbqHD+br1ul8Bpw2x7hLgkpb5c9rWP8YQl5pHRPTbWJ/F1EujvpLa9r3A7C5kiYiYcMrrFzTX01ttSJpJdUyj3Sn18FFExIRS4tBRUz0tEHURGPbKvYiIiSQFIiIiOirx7KSmUiAiIrqo4YOAipS9KgZgAAAONElEQVQCERHRRelBRERERzkGMY4c+cKukTfqshd27ex3BACmDvT/P9y9Oj4gq/dKuEfLa3mh3xEAePjYC/sdgdf/4HP9jjBm0oOIiIiO0oOIiIiOSrxLa1MpEBERXTSpbrURERHNDeQYREREdJIhpoiI6Cg9iIiI6Cg9iIiI6Cg9iIiI6GjA/b84d3elQEREdNF4vlBuxGdSA0iaJelmSZskbZG0QtJUSXMk7ZD0QD19oW2/+ZIs6d27G1DSpS2vZ0i6oG39VZI2SvqRpM9JKuPeDRERVLfaaDqVZsQCUX/h3gistj0PmAdMA66qN9ls+5h6Or9t9yXAd+s/d9elLa9nAC8ViPr52McDbwbeBLwVOGkP2oqIGFMDuPFUmiZDTIuA521/GcD2LkkXAT8GvjjUTnVhOQt4J3CPpH1tPz/M9quBQ4F9gc/aXinpSmCapAeAjcBewBH1/B1UhWtfYB9AwBTgnxp8poiIniixZ9BUkwJxNLC2dYHtZyQ9Vu8/V9I64BngY7bvqTc7HnjU9mZJdwHvofpCH8p5tp+UNA24T9Iq28slfdD2MQCS5gBvGpyvl30H+BlVgVhh+0ftbyxpGbAM4IL9F3Lqfq9r8LEjIvbceL7VRpNjEIKOfR8BU4HDbM8HPgR8TdIB9folwPX16+sZeZjpQknrgTVUPYl5IwaTXge8AZgFHAIsknRi+3a2V9peaHthikNE9NJYH4OQdKqkhyU9Imn5ENu8T9JD9fHZr7UsP0zSt+pjtg/VP7qH1KQHsRE4s63xA4CDgQ22dwDYXitpM3Bk3aM4E1gs6aNUxWSmpP1tb+/wYU4G3gEcZ/u5usexb4NsZwBrbD9bv883gbcBf9tg34iIrhvLYwuS9gI+TzV0v5VqtOUW2w+1bDMP+AhwvO2nJP3rlre4BrjC9h2SpsPwz0Nt0oO4E9hP0rktAT8NrACm1/NIOpzqV/8Wqi/79bYPtT3H9mxgFXD6EG0cCDxVF4ejqL7kB70oaUr9ejuwf8u6nwAnSdq73uYk4BVDTBER/TLGPYhjgUdsb7H9AtXozHvbtvm/gM/bfqpu/+cAkt4I7G37jnr5s7afG66xEQuEq9RnAGdJ2gRsAwZsXwGcCGyoh4ZuAM63/STVcNJNbW+1CjhniGZuA/aWtAG4nGqYadDKuo1rbW8DvifpQUlX121uBn4IrKcqSn8z0meKiOiVAbvxJGmZpPtbpmVtb3cI8HjL/NZ6WasjqUZyvidpjaRTW5Y/LelGSeskXT34A38ojS6Us/04sBheOrX0OkkLbK+i+uJv335ph2W3ALcM8f6/Ak4bYt0lwCUt8+1F5o+bfIaIiH4YzVlMtldS/SgeSqfrvNob2JtqNOdkquOz90h6U738BGA+1ejL/wssBf5yqMZGfSW17XuB2aPdLyJiMhrjs5i2Up3EM2gW8ESHbdbYfhF4VNLDVAVjK7DO9hZ46dKCtzGWBWJPSJpJdUyj3Sn18FFExIQyxjfruw+YJ2ku8FPgbF45dL+aapj/K5JeQzW0tAV4GjhI0mtt/4LqGrf7h2uspwWiLgLHjLhhRMQEMZa3+7a9U9IHgdupLhz+ku2Nkj4B3F8P5d8OvEvSQ8Au4OLBH+CSPgzcWV/IvJZhLnaG3KwvIqKrxvp237ZvBW5tW3ZZy2tTXZf2oQ773kF1a6JGUiAiIrpoot9qIyIidtPAOL7VRgpEREQXpQcREREdjd/yABrP1a1fJC2rL2iZ9DlKyFBKjhIylJKjhAwl5RivGj1RLl6h/fL3fikhRwkZoIwcJWSAMnKUkAHKyTEupUBERERHKRAREdFRCsTuKWVMs4QcJWSAMnKUkAHKyFFCBignx7iUg9QREdFRehAREdFRCkRERHSUAhERER2lQOwBSe/scXsHSDqiw/LGd2ccgwy/Iek36tevlfR7ko7uVfvD5Pp/+tz+3Prv4qget3uYpH3r15L0h5L+XNJ/ktSTOyVIWjyYod8knSjp9fXrfyfpw5L+fb9zjVc5SL0HJP3E9mE9aut9wJ8BPwemAEtt31ev+3vbv9WDDH8MLKd67OH/oHpc4UbgeOAq20M+mWqMc3yufRHwAeAaANsX9iDDatun16/fS/VvcxfwduCTtr/S7Qx12w8Cx9p+TtL/AI6gemDMIgDb5/Ugww7gX4BvAtcBt9ve1e12O+T4M+BYqlsI3Q6cUmc6iepJahf3OtN4lwIxAkkdn6NN9aW0yPare5TjAeA02z+TdCzVl+Gltm+UtM72/B5k+CHw28A04MfA62z/o6SDgO/Y7snDoCRtpfoy/hYvP6P3U8CHAWz/rx5keOnvXNK9wPttP1o/wetO22/pdoa67Ydsv7F+vRZ4q13dPlTS+l7kkLSOqiCdRfWEszcBNwHX2b672+235NhYtz2N6mlrh9SFcwpVgXhTr7JMFLlZ38hOAH4feLZtuah+rfTKXrZ/BmD7B5J+B/jfkmbRu/uBvWj7OeA5SZtt/2Od5ylJvfyl8QbgcuBUqqdl/VTSn/aiMLRo/bx7234UwPY/S+rl/Z0fl7TI9reBx6ieV/zj+vG+vWLbT1E9neyL9RDk+4ArJc2yfejwu49pDrf8/Q/+Gw2Q4fTdkgIxsjXAc51+CdUPA++V7ZKOsL0ZoO5JnEw1nNCrYwADkqbUD0N/aVy3Hn/u2f8BbW8H/qukBcBXJX2jl+3X3iLpGaofClMl/Ubdm9qH6lGQvfJHwDWSPg78Enig/kV/EPDfepRBrTP1D4fPAZ+TNLtHGQC+IekeYF/gL4CvS1pDNcT0tz3MMWFkiGmckPQW4F9sP9K2fArwPtvX9iDDYcATtne2LT8EeIPt/9PtDB0yCbgAOM727/e6/Q55ZlD9XXy/x+2+gerh9HsDW4H7BoeaetD2ybbv6kVbI5F0HFVPYk19QscZwE+Av3a+7EYt3a6G6gOAIy7rFtvrbT/S3mb9a74nZzHZ/kn90PT2DD8FenpGF1R//658frA49PLfpFN7tp8GTu9lhtpS2zfbXmX772wP9OrvYrA49Pv/I3WW71MVBWxvtv0p218HruxljokiBaK5Tl+Ap/U8RRk5SsgAZeQoIQOUkaOEDFBOjnEvxyBGIOk/UQ1hHCFpQ8uq/YF7J1OOEjKUkqOEDKXkKCFDSTkmkhyDGIGkA6kO+H2S6hqAQdttPzmZcpSQoZQcJWQoJUcJGUrKMZGkBzEC278Efilpp+0ft66T9Fe2PzBZcpSQoZQcJWQoJUcJGUrKMZHkGERzv3YqaX0bgwWTNEcJGUrJUUKGUnKUkKGkHONeCsQIJH1E0nbgzZKeqaftwD8BN0+mHCVkKCVHCRlKyVFChpJyTCQ5BtGQpE/a/khylJGhlBwlZCglRwkZSsoxEaRAjIKqew7No7pSEwDbPb9Cs4QcJWQoJUcJGUrJUUKGknKMe7YzNZiobmnwQ+Ap4DvADuDbkzFHCRlKyVFChlJylJChpBwTYcoxiOb+C/BW4Me2fweYD/xikuYoIUMpOUrIUEqOEjKUlGPcS4Fo7nnbzwNImmr7/wNeP0lzlJChlBwlZCglRwkZSsox7uU6iOa21jdiWw3cIekp4IlJmqOEDKXkKCFDKTlKyFBSjnEvB6l3g6STgAOB22y/UC87yNU98SdVjhIylJKjhAyl5CghQ0k5xqsUiDGiHj32czzkKCFDKTlKyFBKjhIylJRjPMgxiLGjkTfpiRJylJAByshRQgYoI0cJGaCcHMVLgRg7pXTFSshRQgYoI0cJGaCMHCVkgHJyFC8FIiIiOkqBGDuldFtLyFFCBigjRwkZoIwcJWSAcnIULwViN0h6taTfl/SNlsWnTMYcJWQoJUcJGUrJUUKGknKMVykQDUnaR9Lpkr4O/IzqP7IvDK537x7O0vccJWQoJUcJGUrJUUKGknJMCP2+10fpE9Xzbb8E/BT4KvC7wGOTMUcJGUrJUUKGUnKUkKGkHBNp6nuA0idgALgbmNuybMtkzFFChlJylJChlBwlZCgpx0SacquNkS0Azgb+j6QtwPXAXpM0RwkZSslRQoZScpSQoaQcE0aupB4FSccDS4AzgQeAm2yvnIw5SshQSo4SMpSSo4QMJeUY71IgdoOkV1GNd55t+w8nc44SMpSSo4QMpeQoIUNJOcarFIhRkjQdOJJqbPPpyZyjhAyl5CghQyk5SshQUo7xLKe5jkDS/2x5/e+Ah4BPAz+U9J7JlKOEDKXkKCFDKTlKyFBSjgml30fJS5+Av295/R3gt+rXhwP3T6YcJWQoJUcJGUrJUUKGknJMpCk9iNE5wPbfA9jeQv/OkCghRwkZSslRQoZScpSQoaQc41pOcx3ZUZI2UN2/Zc7gw0bqg19TJlmOEjKUkqOEDKXkKCFDSTkmjBykHoGk2fXL6VQFdR9gQz1/ku0bJ0uOEjKUkqOEDKXkKCFDSTkmlH6PcZU+Uf3y+DNgG7AWWEd1Kf/yev38yZKjhAyl5CghQyk5SshQUo6JNKUHMQJJnwP2Ay6yvb1edgDwKWAXcKrtuZMhRwkZSslRQoZScpSQoaQcE0kKxAgkPQLMc9tflKS9gH8GTrO9ZjLkKCFDKTlKyFBKjhIylJRjIslZTCMbaP8PDsD2LuAXPfwProQcJWQoJUcJGUrJUUKGknJMGCkQI3tI0rntCyX9PvCjSZajhAyl5CghQyk5SshQUo4JI0NMI5B0CHAjsIPqwJeBtwLTgDNs/3Sy5CghQyk5SshQSo4SMpSUYyJJgWhI0iLgaKpzrDfavnOy5ighQyk5SshQSo4SMpSUYyJIgYiIiI5yDCIiIjpKgYiIiI5SICIioqMUiIiI6CgFIiIiOvr/AUPP/JFR/zUoAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(likeability.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, MaxAbsScaler\n",
    "scl = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q5A_att1</th>\n",
       "      <th>Q5A_att2</th>\n",
       "      <th>Q5A_att3</th>\n",
       "      <th>Q5A_att4</th>\n",
       "      <th>Q5A_att5</th>\n",
       "      <th>Q5A_att6</th>\n",
       "      <th>Q5A_att7</th>\n",
       "      <th>Q5A_att8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.350115</td>\n",
       "      <td>-0.781965</td>\n",
       "      <td>-0.301486</td>\n",
       "      <td>-0.257176</td>\n",
       "      <td>-0.229424</td>\n",
       "      <td>-0.232727</td>\n",
       "      <td>-0.303240</td>\n",
       "      <td>-0.288764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.240316</td>\n",
       "      <td>0.304826</td>\n",
       "      <td>0.264732</td>\n",
       "      <td>0.292882</td>\n",
       "      <td>0.324107</td>\n",
       "      <td>-0.232727</td>\n",
       "      <td>0.266271</td>\n",
       "      <td>0.285240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.350115</td>\n",
       "      <td>-0.781965</td>\n",
       "      <td>-0.301486</td>\n",
       "      <td>0.292882</td>\n",
       "      <td>-0.229424</td>\n",
       "      <td>-0.232727</td>\n",
       "      <td>-0.872751</td>\n",
       "      <td>-0.288764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.421177</td>\n",
       "      <td>0.304826</td>\n",
       "      <td>0.264732</td>\n",
       "      <td>0.292882</td>\n",
       "      <td>-0.229424</td>\n",
       "      <td>0.314301</td>\n",
       "      <td>1.405294</td>\n",
       "      <td>0.285240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.830746</td>\n",
       "      <td>0.848221</td>\n",
       "      <td>0.830950</td>\n",
       "      <td>0.842940</td>\n",
       "      <td>0.877639</td>\n",
       "      <td>1.408356</td>\n",
       "      <td>1.405294</td>\n",
       "      <td>0.859244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Q5A_att1  Q5A_att2  Q5A_att3  Q5A_att4  Q5A_att5  Q5A_att6  Q5A_att7  \\\n",
       "0 -0.350115 -0.781965 -0.301486 -0.257176 -0.229424 -0.232727 -0.303240   \n",
       "1  0.240316  0.304826  0.264732  0.292882  0.324107 -0.232727  0.266271   \n",
       "2 -0.350115 -0.781965 -0.301486  0.292882 -0.229424 -0.232727 -0.872751   \n",
       "3  1.421177  0.304826  0.264732  0.292882 -0.229424  0.314301  1.405294   \n",
       "4  0.830746  0.848221  0.830950  0.842940  0.877639  1.408356  1.405294   \n",
       "\n",
       "   Q5A_att8  \n",
       "0 -0.288764  \n",
       "1  0.285240  \n",
       "2 -0.288764  \n",
       "3  0.285240  \n",
       "4  0.859244  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "likeability_std = scl.fit_transform(likeability)\n",
    "likeability_std = pd.DataFrame(likeability_std,columns=likeability.columns)\n",
    "likeability_std.to_csv('likeability_std.csv',index=False)\n",
    "likeability_std.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above plots we can see that there is significant correlation among the variables.\n",
    "\n",
    "To handle this we can use Principal Component Analysis and remove few of the attributes that do not explain much of the variance and hence reduce the dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principal Component Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the Principal Component Analysis we will also consider the attribute After-Taste as it may explain some part of the variance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "      <th>PC4</th>\n",
       "      <th>PC5</th>\n",
       "      <th>PC6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.887055</td>\n",
       "      <td>0.465339</td>\n",
       "      <td>0.095885</td>\n",
       "      <td>-0.156038</td>\n",
       "      <td>-0.106431</td>\n",
       "      <td>0.038368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.565220</td>\n",
       "      <td>-0.204215</td>\n",
       "      <td>0.137311</td>\n",
       "      <td>-0.238494</td>\n",
       "      <td>0.146587</td>\n",
       "      <td>-0.205819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.900379</td>\n",
       "      <td>0.436403</td>\n",
       "      <td>-0.433586</td>\n",
       "      <td>-0.542759</td>\n",
       "      <td>-0.321796</td>\n",
       "      <td>0.282032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.005782</td>\n",
       "      <td>0.280622</td>\n",
       "      <td>-0.007703</td>\n",
       "      <td>0.483494</td>\n",
       "      <td>0.616515</td>\n",
       "      <td>-0.784998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.679122</td>\n",
       "      <td>0.203479</td>\n",
       "      <td>-0.016058</td>\n",
       "      <td>0.415319</td>\n",
       "      <td>-0.091785</td>\n",
       "      <td>-0.187008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        PC1       PC2       PC3       PC4       PC5       PC6\n",
       "0  0.887055  0.465339  0.095885 -0.156038 -0.106431  0.038368\n",
       "1 -0.565220 -0.204215  0.137311 -0.238494  0.146587 -0.205819\n",
       "2  0.900379  0.436403 -0.433586 -0.542759 -0.321796  0.282032\n",
       "3 -1.005782  0.280622 -0.007703  0.483494  0.616515 -0.784998\n",
       "4 -2.679122  0.203479 -0.016058  0.415319 -0.091785 -0.187008"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "mypca = PCA(n_components=6)\n",
    "PCs = mypca.fit_transform(likeability_std[['Q5A_att2','Q5A_att3','Q5A_att4','Q5A_att5','Q5A_att6','Q5A_att7','Q5A_att8']])\n",
    "PCs = pd.DataFrame(PCs,columns=['PC1','PC2','PC3','PC4','PC5','PC6'])\n",
    "PCs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.48454962, 0.43112695, 0.27585087, 0.2523241 , 0.22033185,\n",
       "       0.17910657])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mypca.explained_variance_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.78316344, 0.06156255, 0.03938998, 0.03603049, 0.03146217,\n",
       "       0.02557543])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mypca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After performing the Principal Component analysis we can see that the the first PC is explaining 78% of the variance.\n",
    "\n",
    "So if we retain the first three principal components we can expalin 90% of the variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "      <th>Q5A_att1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.836983</td>\n",
       "      <td>0.463675</td>\n",
       "      <td>0.167813</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.502205</td>\n",
       "      <td>-0.220612</td>\n",
       "      <td>0.157980</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.611425</td>\n",
       "      <td>0.603628</td>\n",
       "      <td>-0.113191</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.500328</td>\n",
       "      <td>0.029217</td>\n",
       "      <td>-0.382574</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.314988</td>\n",
       "      <td>0.124968</td>\n",
       "      <td>-0.180056</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        PC1       PC2       PC3  Q5A_att1\n",
       "0  0.836983  0.463675  0.167813         7\n",
       "1 -0.502205 -0.220612  0.157980         8\n",
       "2  0.611425  0.603628 -0.113191         7\n",
       "3 -0.500328  0.029217 -0.382574        10\n",
       "4 -2.314988  0.124968 -0.180056         9"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mypca = PCA(n_components=3)\n",
    "data_pc = mypca.fit_transform(likeability_std[['Q5A_att2', 'Q5A_att3','Q5A_att4', 'Q5A_att5', 'Q5A_att6', 'Q5A_att8']])\n",
    "data_pc = pd.DataFrame(data_pc,columns=['PC1','PC2','PC3'])\n",
    "data_pc.loc[:,'Q5A_att1'] = likeability['Q5A_att1']\n",
    "data_pc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.37572381, -0.4191673 , -0.41006154, -0.41153483, -0.41299715,\n",
       "        -0.41839259],\n",
       "       [-0.85150015,  0.00158225,  0.25443338, -0.10979345,  0.34560456,\n",
       "         0.28055574],\n",
       "       [-0.31207057,  0.26097568, -0.51086167,  0.67679523, -0.30332503,\n",
       "         0.15318665]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mypca.components_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Factor Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to look which all attributes are contributing to the principal components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Rotated Component matrix gives us this information.\n",
    "We need to check which attributes are contributing most in which Principle Component.\n",
    "\n",
    "To do this we have used R and performed PCA to get the Rotated Component Matrix of Principal components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import rpy2\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%R -i likeability_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <span>ListVector with 30 elements.</span>\n",
       "    <table>\n",
       "      <tbody>\n",
       "      \n",
       "      <tr>\n",
       "      <th>\n",
       "        values\n",
       "      </th>\n",
       "      <td>\n",
       "        \n",
       "    <span>FloatVector with 7 elements.</span>\n",
       "    <table>\n",
       "      <tbody>\n",
       "      <tr>\n",
       "      \n",
       "      <td>\n",
       "        5.482144\n",
       "      </td>\n",
       "      \n",
       "      <td>\n",
       "        0.430938\n",
       "      </td>\n",
       "      \n",
       "      <td>\n",
       "        0.275730\n",
       "      </td>\n",
       "      \n",
       "      <td>\n",
       "        0.252213\n",
       "      </td>\n",
       "      \n",
       "      <td>\n",
       "        0.220235\n",
       "      </td>\n",
       "      \n",
       "      <td>\n",
       "        0.179028\n",
       "      </td>\n",
       "      \n",
       "      <td>\n",
       "        0.159711\n",
       "      </td>\n",
       "      \n",
       "      </tr>\n",
       "      </tbody>\n",
       "    </table>\n",
       "    \n",
       "      </td>\n",
       "      </tr>\n",
       "      \n",
       "      <tr>\n",
       "      <th>\n",
       "        rotation\n",
       "      </th>\n",
       "      <td>\n",
       "        \n",
       "    <span>StrVector with 1 elements.</span>\n",
       "    <table>\n",
       "      <tbody>\n",
       "      <tr>\n",
       "      \n",
       "      <td>\n",
       "        'varimax'\n",
       "      </td>\n",
       "      \n",
       "      </tr>\n",
       "      </tbody>\n",
       "    </table>\n",
       "    \n",
       "      </td>\n",
       "      </tr>\n",
       "      \n",
       "      <tr>\n",
       "      <th>\n",
       "        n.obs\n",
       "      </th>\n",
       "      <td>\n",
       "        \n",
       "    <span>IntVector with 1 elements.</span>\n",
       "    <table>\n",
       "      <tbody>\n",
       "      <tr>\n",
       "      \n",
       "      <td>\n",
       "        2,280\n",
       "      </td>\n",
       "      \n",
       "      </tr>\n",
       "      </tbody>\n",
       "    </table>\n",
       "    \n",
       "      </td>\n",
       "      </tr>\n",
       "      \n",
       "      <tr>\n",
       "      <th>\n",
       "        ...\n",
       "      </th>\n",
       "      <td>\n",
       "        ...\n",
       "      </td>\n",
       "      </tr>\n",
       "      \n",
       "      <tr>\n",
       "      <th>\n",
       "        Vaccounted\n",
       "      </th>\n",
       "      <td>\n",
       "        \n",
       "    <span>Matrix with 15 elements.</span>\n",
       "    <table>\n",
       "      <tbody>\n",
       "      <tr>\n",
       "      \n",
       "      <td>\n",
       "        2.593077\n",
       "      </td>\n",
       "      \n",
       "      <td>\n",
       "        0.370440\n",
       "      </td>\n",
       "      \n",
       "      <td>\n",
       "        0.370440\n",
       "      </td>\n",
       "      \n",
       "      <td>\n",
       "        0.418994\n",
       "      </td>\n",
       "      \n",
       "      <td>\n",
       "        ...\n",
       "      </td>\n",
       "      \n",
       "      <td>\n",
       "        0.212871\n",
       "      </td>\n",
       "      \n",
       "      <td>\n",
       "        0.884116\n",
       "      </td>\n",
       "      \n",
       "      <td>\n",
       "        0.240772\n",
       "      </td>\n",
       "      \n",
       "      <td>\n",
       "        1.000000\n",
       "      </td>\n",
       "      \n",
       "      </tr>\n",
       "      </tbody>\n",
       "    </table>\n",
       "    \n",
       "      </td>\n",
       "      </tr>\n",
       "      \n",
       "      <tr>\n",
       "      <th>\n",
       "        Structure\n",
       "      </th>\n",
       "      <td>\n",
       "        \n",
       "    <span>Matrix with 21 elements.</span>\n",
       "    <table>\n",
       "      <tbody>\n",
       "      <tr>\n",
       "      \n",
       "      <td>\n",
       "        0.328115\n",
       "      </td>\n",
       "      \n",
       "      <td>\n",
       "        0.644848\n",
       "      </td>\n",
       "      \n",
       "      <td>\n",
       "        0.358657\n",
       "      </td>\n",
       "      \n",
       "      <td>\n",
       "        0.769445\n",
       "      </td>\n",
       "      \n",
       "      <td>\n",
       "        ...\n",
       "      </td>\n",
       "      \n",
       "      <td>\n",
       "        0.446708\n",
       "      </td>\n",
       "      \n",
       "      <td>\n",
       "        0.261051\n",
       "      </td>\n",
       "      \n",
       "      <td>\n",
       "        0.271301\n",
       "      </td>\n",
       "      \n",
       "      <td>\n",
       "        0.253222\n",
       "      </td>\n",
       "      \n",
       "      </tr>\n",
       "      </tbody>\n",
       "    </table>\n",
       "    \n",
       "      </td>\n",
       "      </tr>\n",
       "      \n",
       "      <tr>\n",
       "      <th>\n",
       "        scores\n",
       "      </th>\n",
       "      <td>\n",
       "        \n",
       "    <span>Matrix with 6840 elements.</span>\n",
       "    <table>\n",
       "      <tbody>\n",
       "      <tr>\n",
       "      \n",
       "      <td>\n",
       "        0.042954\n",
       "      </td>\n",
       "      \n",
       "      <td>\n",
       "        0.273118\n",
       "      </td>\n",
       "      \n",
       "      <td>\n",
       "        -0.685239\n",
       "      </td>\n",
       "      \n",
       "      <td>\n",
       "        0.375637\n",
       "      </td>\n",
       "      \n",
       "      <td>\n",
       "        ...\n",
       "      </td>\n",
       "      \n",
       "      <td>\n",
       "        -1.150503\n",
       "      </td>\n",
       "      \n",
       "      <td>\n",
       "        0.275628\n",
       "      </td>\n",
       "      \n",
       "      <td>\n",
       "        0.291286\n",
       "      </td>\n",
       "      \n",
       "      <td>\n",
       "        -1.150503\n",
       "      </td>\n",
       "      \n",
       "      </tr>\n",
       "      </tbody>\n",
       "    </table>\n",
       "    \n",
       "      </td>\n",
       "      </tr>\n",
       "      \n",
       "      </tbody>\n",
       "    </table>\n",
       "    "
      ],
      "text/plain": [
       "R object with classes: ('psych', 'principal') mapped to:\n",
       "<ListVector - Python:0x000002338976E248 / R:0x00000233887A7050>\n",
       "[FloatVector, StrVector, IntVector, FloatVector, ..., Matrix, Matrix, Matrix, Matrix]\n",
       "  values: <class 'rpy2.robjects.vectors.FloatVector'>\n",
       "  R object with classes: ('numeric',) mapped to:\n",
       "<FloatVector - Python:0x0000023389757388 / R:0x0000023387F0C578>\n",
       "[5.482144, 0.430938, 0.275730, 0.252213, 0.220235, 0.179028, 0.159711]\n",
       "  rotation: <class 'rpy2.robjects.vectors.StrVector'>\n",
       "  R object with classes: ('character',) mapped to:\n",
       "<StrVector - Python:0x00000233897A82C8 / R:0x000002338A3A3E38>\n",
       "['varimax']\n",
       "  n.obs: <class 'rpy2.robjects.vectors.IntVector'>\n",
       "  R object with classes: ('integer',) mapped to:\n",
       "<IntVector - Python:0x0000023389798DC8 / R:0x000002338A5E0328>\n",
       "[2,280]\n",
       "  communality: <class 'rpy2.robjects.vectors.FloatVector'>\n",
       "  R object with classes: ('numeric',) mapped to:\n",
       "<FloatVector - Python:0x0000023386133EC8 / R:0x0000023389AEEEE0>\n",
       "[0.976375, 0.824036, 0.922291, 0.875533, 0.858814, 0.863137, 0.868625]\n",
       "...\n",
       "  fit: <class 'rpy2.robjects.vectors.Matrix'>\n",
       "  R object with classes: ('matrix',) mapped to:\n",
       "<Matrix - Python:0x00000233897989C8 / R:0x0000023388B4AD18>\n",
       "[0.665929, -0.234049, -0.708350, 0.458581, ..., 0.141227, 0.588423, -0.418883, 0.691589]\n",
       "  fit.off: <class 'rpy2.robjects.vectors.Matrix'>\n",
       "  R object with classes: ('matrix',) mapped to:\n",
       "<Matrix - Python:0x00000233897A8188 / R:0x0000023388B43290>\n",
       "[2.593077, 0.370440, 0.370440, 0.418994, ..., 0.212871, 0.884116, 0.240772, 1.000000]\n",
       "  fn: <class 'rpy2.robjects.vectors.Matrix'>\n",
       "  R object with classes: ('loadings',) mapped to:\n",
       "<Matrix - Python:0x0000023389798C48 / R:0x0000023388CE5FF8>\n",
       "[0.328115, 0.644848, 0.358657, 0.769445, ..., 0.446708, 0.261051, 0.271301, 0.253222]\n",
       "  Call: <class 'rpy2.robjects.vectors.Matrix'>\n",
       "  R object with classes: ('matrix',) mapped to:\n",
       "<Matrix - Python:0x00000233899DC5C8 / R:0x000002338A627940>\n",
       "[0.042954, 0.273118, -0.685239, 0.375637, ..., -1.150503, 0.275628, 0.291286, -1.150503]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%R require(psych)\n",
    "%R pca1 = principal(likeability_std[2:8],nfactors = 3,scores = TRUE) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eigen Values of the principal Components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.48214411, 0.43093786, 0.27572989, 0.25221344, 0.22023521,\n",
       "       0.17902801, 0.15971149])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%R pca1$values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eigen Values of the principal Components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the Rotated Component Matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Q5A_att2</th>\n",
       "      <td>0.328115</td>\n",
       "      <td>0.305421</td>\n",
       "      <td>0.880587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q5A_att3</th>\n",
       "      <td>0.644848</td>\n",
       "      <td>0.475510</td>\n",
       "      <td>0.426730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q5A_att4</th>\n",
       "      <td>0.358657</td>\n",
       "      <td>0.816404</td>\n",
       "      <td>0.356568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q5A_att5</th>\n",
       "      <td>0.769445</td>\n",
       "      <td>0.289724</td>\n",
       "      <td>0.446708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q5A_att6</th>\n",
       "      <td>0.538378</td>\n",
       "      <td>0.707683</td>\n",
       "      <td>0.261051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q5A_att7</th>\n",
       "      <td>0.736495</td>\n",
       "      <td>0.497100</td>\n",
       "      <td>0.271301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Q5A_att8</th>\n",
       "      <td>0.718772</td>\n",
       "      <td>0.536536</td>\n",
       "      <td>0.253222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                F1        F2        F3\n",
       "Q5A_att2  0.328115  0.305421  0.880587\n",
       "Q5A_att3  0.644848  0.475510  0.426730\n",
       "Q5A_att4  0.358657  0.816404  0.356568\n",
       "Q5A_att5  0.769445  0.289724  0.446708\n",
       "Q5A_att6  0.538378  0.707683  0.261051\n",
       "Q5A_att7  0.736495  0.497100  0.271301\n",
       "Q5A_att8  0.718772  0.536536  0.253222"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FA = %R pca1$Structure\n",
    "FA = pd.DataFrame(FA,columns=['F1','F2','F3'],index=likeability_std.drop('Q5A_att1',axis=1).columns)\n",
    "FA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the Rotated Component Matrix we can observe the following:\n",
    "    \n",
    "- 5A_Attr2(Aroma) - F3\n",
    "- 5A_Attr3 (Taste) - F1\n",
    "- 5A_Attr4 (Smoothness) - F2\n",
    "- 5A_Attr5 (Flavour) - F1\n",
    "- 5A_Attr6 (Throat-feel when the vodka goes down) - F2\n",
    "- 5A_Attr7 (After-taste) - F1\n",
    "- 5A_Attr8 (Mouth-feel when the vodka is sipped) - F2\n",
    "\n",
    "Factors: \n",
    "- F1 = Taste, Flavour, After-taste\n",
    "- F2 = Smoothness, Throat-feel when the vodka goes down, Mouth-feel when the vodka is sipped\n",
    "- F3 = Aroma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above details we can name the Factors:\n",
    "    - Taste = Factor 1 has attributes that are related to taste.\n",
    "    - Feel = Factor 2 has attributes related to Strength and Feel of the Vodka.\n",
    "    - Smell = Factor 3 has only one attribute that is related to the smell of the vodka."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PCs = %R pca1$scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "      <th>Q5A_att1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.042954</td>\n",
       "      <td>-0.052273</td>\n",
       "      <td>-0.821272</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.273118</td>\n",
       "      <td>-0.169071</td>\n",
       "      <td>0.346631</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.685239</td>\n",
       "      <td>0.623113</td>\n",
       "      <td>-0.642846</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.375637</td>\n",
       "      <td>0.441877</td>\n",
       "      <td>-0.175951</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.812690</td>\n",
       "      <td>0.824105</td>\n",
       "      <td>0.257039</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        PC1       PC2       PC3  Q5A_att1\n",
       "0  0.042954 -0.052273 -0.821272         7\n",
       "1  0.273118 -0.169071  0.346631         8\n",
       "2 -0.685239  0.623113 -0.642846         7\n",
       "3  0.375637  0.441877 -0.175951        10\n",
       "4  0.812690  0.824105  0.257039         9"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PCs = pd.DataFrame(PCs,columns=['PC1','PC2','PC3'])\n",
    "PCs.loc[:,'Q5A_att1'] = likeability['Q5A_att1']\n",
    "PCs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding the Target column to the Factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:               Q5A_att1   R-squared:                       0.767\n",
      "Model:                            OLS   Adj. R-squared:                  0.766\n",
      "Method:                 Least Squares   F-statistic:                     2493.\n",
      "Date:                Wed, 13 Jun 2018   Prob (F-statistic):               0.00\n",
      "Time:                        21:48:45   Log-Likelihood:                -2777.3\n",
      "No. Observations:                2280   AIC:                             5563.\n",
      "Df Residuals:                    2276   BIC:                             5586.\n",
      "Df Model:                           3                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      7.5930      0.017    442.810      0.000       7.559       7.627\n",
      "PC1            0.9637      0.017     56.191      0.000       0.930       0.997\n",
      "PC2            0.8464      0.017     49.348      0.000       0.813       0.880\n",
      "PC3            0.7451      0.017     43.444      0.000       0.711       0.779\n",
      "==============================================================================\n",
      "Omnibus:                      143.861   Durbin-Watson:                   1.723\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              495.069\n",
      "Skew:                          -0.238   Prob(JB):                    3.14e-108\n",
      "Kurtosis:                       5.233   Cond. No.                         1.00\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.formula.api as sm\n",
    "m = sm.ols(formula=\"Q5A_att1~PC1+PC2+PC3\",data=PCs)\n",
    "AR = m.fit()\n",
    "print(AR.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of Squared Residuals =  1525.7986991764565\n"
     ]
    }
   ],
   "source": [
    "print(\"Sum of Squared Residuals = \",AR.ssr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe the following differences in the output after removing Q5A_att7(After-Taste):\n",
    "\n",
    "- The F Statistic value has increased from 1302 to 2493.\n",
    "- The R2 value has decreased Slightly.\n",
    "- All the Factors are significantly contributing in the explanation of Variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus from the above analysis we have derived the following Factors\n",
    "- Taste = Factor 1 has attributes that are related to taste.\n",
    "- Feel = Factor 2 has attributes related to Strength and Feel of the Vodka.\n",
    "- Smell = Factor 3 has only one attribute that is related to the smell of the vodka."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
